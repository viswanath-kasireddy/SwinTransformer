{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "V100"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "71oikck2sMst",
        "outputId": "1972fee4-395c-4dab-9e3e-37c77a7865ea"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "import tensorflow as tf\n",
        "tf.config.run_functions_eagerly(True)\n",
        "\n",
        "from tensorflow.keras.utils import image_dataset_from_directory\n",
        "\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Input, Dropout, Dense, Flatten, Conv2D, MaxPooling2D\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.applications import regnet\n",
        "\n",
        "# Initialize rng\n",
        "rng = np.random.default_rng(2022)\n",
        "\n",
        "auc = tf.keras.metrics.AUC()"
      ],
      "metadata": {
        "id": "FEQ4Y6aG0bvW"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from keras import backend as K\n",
        "\n",
        "def recall_m(y_true, y_pred):\n",
        "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
        "    possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
        "    recall = true_positives / (possible_positives + K.epsilon())\n",
        "    return recall\n",
        "\n",
        "def precision_m(y_true, y_pred):\n",
        "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
        "    predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
        "    precision = true_positives / (predicted_positives + K.epsilon())\n",
        "    return precision\n",
        "\n",
        "def f1_m(y_true, y_pred):\n",
        "    precision = precision_m(y_true, y_pred)\n",
        "    recall = recall_m(y_true, y_pred)\n",
        "    return 2*((precision*recall)/(precision+recall+K.epsilon()))"
      ],
      "metadata": {
        "id": "7qiT9GL10ccY"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 32 # This is a tunable hyperparameter\n",
        "shape = (128, 128) # note we are reducing the size of the image\n",
        "# Note: you will use 'grayscale' images for your own model\n",
        "# but you might need to switch to 'rgb' for pretrained models because they are trained on ImageNet which has only RGB images\n",
        "data_dir = '/content/drive/MyDrive/Final_Project/Dataset'\n",
        "train_ds_new = tf.keras.utils.image_dataset_from_directory(os.path.join(data_dir, 'train_new'),\n",
        "                                                       seed=rng.integers(500000),\n",
        "                                                       image_size=shape,\n",
        "                                                       label_mode=\"categorical\",\n",
        "                                                       color_mode='grayscale',\n",
        "                                                       batch_size=batch_size)\n",
        "val_ds = tf.keras.utils.image_dataset_from_directory(os.path.join(data_dir, 'validation/validation'),\n",
        "                                                     seed=rng.integers(500000),\n",
        "                                                     image_size=shape,\n",
        "                                                     label_mode=\"categorical\",\n",
        "                                                     color_mode='grayscale',\n",
        "                                                     batch_size=batch_size)\n",
        "test_ds = tf.keras.utils.image_dataset_from_directory(os.path.join(data_dir, 'test_new'),\n",
        "                                                      seed=rng.integers(500000),\n",
        "                                                      image_size=shape,\n",
        "                                                      label_mode=\"categorical\",\n",
        "                                                      color_mode='grayscale',\n",
        "                                                      batch_size=batch_size)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7-V0Qspl0ehN",
        "outputId": "763828fc-6f90-48ee-d8cc-b92dd21bc1e4"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 16000 files belonging to 4 classes.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/tensorflow/python/data/ops/structured_function.py:258: UserWarning: Even though the `tf.config.experimental_run_functions_eagerly` option is set, this option does not apply to tf.data functions. To force eager execution of tf.data functions, please use `tf.data.experimental.enable_debug_mode()`.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 4000 files belonging to 4 classes.\n",
            "Found 4000 files belonging to 4 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for images, _ in train_ds_new.take(1):\n",
        "    print(\"Image batch shape: \", images.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VynMjXrj0_Ap",
        "outputId": "ec7468fb-76a1-4580-9ced-bd097841cd52"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Image batch shape:  (32, 128, 128, 1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def normalize(image, label):\n",
        "    image = tf.cast(image, tf.float32) / 255.0\n",
        "    return image, label\n",
        "\n",
        "train_ds_new = train_ds_new.map(normalize)\n",
        "val_ds = val_ds.map(normalize)\n",
        "test_ds = test_ds.map(normalize)\n"
      ],
      "metadata": {
        "id": "kOyDCIqc14bO"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.layers.experimental import preprocessing\n",
        "\n",
        "# Data augmentation layers\n",
        "data_augmentation_layers = tf.keras.Sequential([\n",
        "    preprocessing.RandomFlip(\"horizontal_and_vertical\"),\n",
        "    preprocessing.RandomRotation(0.2),\n",
        "    preprocessing.RandomZoom(0.2),\n",
        "])\n",
        "\n",
        "# Adding data augmentation to the training dataset\n",
        "def augment_data(image, label):\n",
        "    return data_augmentation_layers(image), label\n",
        "\n",
        "train_ds_new = train_ds_new.map(augment_data)\n"
      ],
      "metadata": {
        "id": "Pfc-lsPaSi2S"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Conv2DTranspose\n",
        "from tensorflow.keras.layers import Input, Flatten, Dense, Dropout\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.metrics import Precision, Recall, CategoricalAccuracy\n",
        "\n",
        "def encoder(inputs):\n",
        "    x = Conv2D(32, (3, 3), activation='relu', padding='same')(inputs)\n",
        "    x = MaxPooling2D((2, 2), padding='same')(x)\n",
        "    x = Dropout(0.25)(x)  # Added dropout\n",
        "    x = Conv2D(64, (3, 3), activation='relu', padding='same')(x)\n",
        "    x = MaxPooling2D((2, 2), padding='same')(x)\n",
        "    x = Dropout(0.25)(x)  # Added dropout\n",
        "    # Additional layer\n",
        "    x = Conv2D(128, (3, 3), activation='relu', padding='same')(x)\n",
        "    x = MaxPooling2D((2, 2), padding='same')(x)\n",
        "    return x\n",
        "\n",
        "def decoder(encoded):\n",
        "    x = Conv2DTranspose(128, (3, 3), strides=2, activation='relu', padding='same')(encoded)\n",
        "    x = Dropout(0.25)(x)  # Added dropout\n",
        "    x = Conv2DTranspose(64, (3, 3), strides=2, activation='relu', padding='same')(x)\n",
        "    x = Dropout(0.25)(x)  # Added dropout\n",
        "    x = Conv2DTranspose(32, (3, 3), strides=2, activation='relu', padding='same')(x)\n",
        "    x = Conv2D(1, (3, 3), activation='sigmoid', padding='same')(x)\n",
        "    return x\n",
        "\n",
        "\n",
        "from tensorflow.keras.regularizers import l2\n",
        "\n",
        "def classifier(encoded):\n",
        "    x = Flatten()(encoded)\n",
        "    x = Dense(128, activation='relu', kernel_regularizer=l2(0.001))(x)  # Added L2 regularization\n",
        "    x = Dropout(0.5)(x)\n",
        "    x = Dense(4, activation='softmax', kernel_regularizer=l2(0.001))(x)  # Added L2 regularization\n",
        "    return x\n",
        "\n",
        "\n",
        "input_img = Input(shape=(128, 128, 1))  # Make sure this shape matches your dataset\n",
        "\n",
        "# Build the autoencoder\n",
        "encoded = encoder(input_img)\n",
        "decoded = decoder(encoded)\n",
        "\n",
        "# Build the classifier\n",
        "classification_output = classifier(encoded)\n",
        "\n",
        "# Full model\n",
        "autoencoder_classifier = Model(inputs=input_img, outputs=[decoded, classification_output])\n",
        "\n",
        "# Compile the model with multiple outputs and loss functions\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# Now you can proceed to train the model with train_ds_new and validate with val_ds\n",
        "# Remember to use a one-hot encoded format for your labels if you're using 'categorical_crossentropy'\n"
      ],
      "metadata": {
        "id": "skYoWTbT4Iim"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "autoencoder_classifier.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jWPxNRwg612J",
        "outputId": "b8b5ad02-20a6-4563-be77-741c7f51b541"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                Output Shape                 Param #   Connected to                  \n",
            "==================================================================================================\n",
            " input_1 (InputLayer)        [(None, 128, 128, 1)]        0         []                            \n",
            "                                                                                                  \n",
            " conv2d (Conv2D)             (None, 128, 128, 32)         320       ['input_1[0][0]']             \n",
            "                                                                                                  \n",
            " max_pooling2d (MaxPooling2  (None, 64, 64, 32)           0         ['conv2d[0][0]']              \n",
            " D)                                                                                               \n",
            "                                                                                                  \n",
            " dropout (Dropout)           (None, 64, 64, 32)           0         ['max_pooling2d[0][0]']       \n",
            "                                                                                                  \n",
            " conv2d_1 (Conv2D)           (None, 64, 64, 64)           18496     ['dropout[0][0]']             \n",
            "                                                                                                  \n",
            " max_pooling2d_1 (MaxPoolin  (None, 32, 32, 64)           0         ['conv2d_1[0][0]']            \n",
            " g2D)                                                                                             \n",
            "                                                                                                  \n",
            " dropout_1 (Dropout)         (None, 32, 32, 64)           0         ['max_pooling2d_1[0][0]']     \n",
            "                                                                                                  \n",
            " conv2d_2 (Conv2D)           (None, 32, 32, 128)          73856     ['dropout_1[0][0]']           \n",
            "                                                                                                  \n",
            " max_pooling2d_2 (MaxPoolin  (None, 16, 16, 128)          0         ['conv2d_2[0][0]']            \n",
            " g2D)                                                                                             \n",
            "                                                                                                  \n",
            " conv2d_transpose (Conv2DTr  (None, 32, 32, 128)          147584    ['max_pooling2d_2[0][0]']     \n",
            " anspose)                                                                                         \n",
            "                                                                                                  \n",
            " dropout_2 (Dropout)         (None, 32, 32, 128)          0         ['conv2d_transpose[0][0]']    \n",
            "                                                                                                  \n",
            " conv2d_transpose_1 (Conv2D  (None, 64, 64, 64)           73792     ['dropout_2[0][0]']           \n",
            " Transpose)                                                                                       \n",
            "                                                                                                  \n",
            " flatten (Flatten)           (None, 32768)                0         ['max_pooling2d_2[0][0]']     \n",
            "                                                                                                  \n",
            " dropout_3 (Dropout)         (None, 64, 64, 64)           0         ['conv2d_transpose_1[0][0]']  \n",
            "                                                                                                  \n",
            " dense (Dense)               (None, 128)                  4194432   ['flatten[0][0]']             \n",
            "                                                                                                  \n",
            " conv2d_transpose_2 (Conv2D  (None, 128, 128, 32)         18464     ['dropout_3[0][0]']           \n",
            " Transpose)                                                                                       \n",
            "                                                                                                  \n",
            " dropout_4 (Dropout)         (None, 128)                  0         ['dense[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_3 (Conv2D)           (None, 128, 128, 1)          289       ['conv2d_transpose_2[0][0]']  \n",
            "                                                                                                  \n",
            " dense_1 (Dense)             (None, 4)                    516       ['dropout_4[0][0]']           \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 4527749 (17.27 MB)\n",
            "Trainable params: 4527749 (17.27 MB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class F1Score(tf.keras.metrics.Metric):\n",
        "    def __init__(self, name='f1_score', **kwargs):\n",
        "        super(F1Score, self).__init__(name=name, **kwargs)\n",
        "        self.precision = tf.keras.metrics.Precision()\n",
        "        self.recall = tf.keras.metrics.Recall()\n",
        "\n",
        "    def update_state(self, y_true, y_pred, sample_weight=None):\n",
        "        y_pred = tf.round(y_pred)\n",
        "        self.precision.update_state(y_true, y_pred, sample_weight)\n",
        "        self.recall.update_state(y_true, y_pred, sample_weight)\n",
        "\n",
        "    def result(self):\n",
        "        p = self.precision.result()\n",
        "        r = self.recall.result()\n",
        "        return 2 * ((p * r) / (p + r + tf.keras.backend.epsilon()))\n",
        "\n",
        "    def reset_states(self):\n",
        "        self.precision.reset_states()\n",
        "        self.recall.reset_states()\n"
      ],
      "metadata": {
        "id": "HGBbne7dBHMF"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "autoencoder_classifier.compile(\n",
        "    optimizer='adam',\n",
        "    loss=['mse', 'categorical_crossentropy'],  # mse for reconstruction, categorical_crossentropy for classification\n",
        "    metrics={\n",
        "        'conv2d_3': ['accuracy'],  # Assuming 'conv2d_11' is your decoder output - accuracy might not be meaningful here\n",
        "        'dense_1': ['accuracy', Precision(), Recall(), F1Score()]  # Assuming 'dense_7' is your classification output\n",
        "    }\n",
        ")"
      ],
      "metadata": {
        "id": "7Xzo75Cg9Bgy"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t6G6toIc4U4q",
        "outputId": "570923b6-858a-4076-dbf3-730ccfef69fc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[0. 1. 0. 0.]\n",
            " [0. 0. 0. 1.]\n",
            " [0. 0. 1. 0.]\n",
            " [0. 0. 1. 0.]\n",
            " [1. 0. 0. 0.]\n",
            " [0. 0. 0. 1.]\n",
            " [0. 1. 0. 0.]\n",
            " [0. 1. 0. 0.]\n",
            " [0. 0. 1. 0.]\n",
            " [0. 1. 0. 0.]\n",
            " [0. 0. 1. 0.]\n",
            " [0. 0. 1. 0.]\n",
            " [1. 0. 0. 0.]\n",
            " [0. 0. 1. 0.]\n",
            " [1. 0. 0. 0.]\n",
            " [0. 0. 0. 1.]\n",
            " [0. 0. 0. 1.]\n",
            " [1. 0. 0. 0.]\n",
            " [0. 0. 1. 0.]\n",
            " [0. 0. 0. 1.]\n",
            " [0. 1. 0. 0.]\n",
            " [0. 0. 1. 0.]\n",
            " [0. 0. 1. 0.]\n",
            " [0. 0. 0. 1.]\n",
            " [0. 1. 0. 0.]\n",
            " [0. 0. 1. 0.]\n",
            " [0. 0. 1. 0.]\n",
            " [1. 0. 0. 0.]\n",
            " [0. 1. 0. 0.]\n",
            " [0. 0. 1. 0.]\n",
            " [0. 0. 1. 0.]\n",
            " [0. 0. 1. 0.]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_ds_new = train_ds_new.map(augment_data).repeat()\n",
        "val_ds = val_ds.repeat()\n",
        "\n",
        "def data_generator(dataset):\n",
        "    for images, labels in dataset:\n",
        "        yield images, [images, labels]\n",
        "\n",
        "train_generator = data_generator(train_ds_new)\n",
        "val_generator = data_generator(val_ds)\n",
        "\n",
        "train_batch_size = 32\n",
        "val_batch_size = 32  # Can be different from train_batch_size if needed\n",
        "\n"
      ],
      "metadata": {
        "id": "HitHE1ywTVqk"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_steps_per_epoch = 16000 // batch_size\n",
        "val_steps_per_epoch = 4000 // batch_size\n",
        "\n",
        "# Adjust for any remaining images not fitting into a full batch\n",
        "if 16000 % batch_size != 0:\n",
        "    train_steps_per_epoch += 1\n",
        "if 4000 % batch_size != 0:\n",
        "    val_steps_per_epoch += 1\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# Train the model using these generators\n",
        "autoencoder_classifier.fit(\n",
        "    train_generator,\n",
        "    epochs=50,  # Or your desired number of epochs\n",
        "    steps_per_epoch=train_steps_per_epoch,\n",
        "    validation_data=val_generator,\n",
        "    validation_steps=val_steps_per_epoch\n",
        ")\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 463
        },
        "id": "XJuqEoGF4YS2",
        "outputId": "6b062789-3b70-4d3c-ff02-da7bf8d96245"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "193/500 [==========>...................] - ETA: 10:16 - loss: 1.4924 - conv2d_3_loss: 0.0250 - dense_1_loss: 1.3893 - conv2d_3_accuracy: 0.0078 - dense_1_accuracy: 0.2581 - dense_1_precision: 0.2222 - dense_1_recall: 6.4767e-04 - dense_1_f1_score: 0.0013"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-13-bf82f7b0d1ab>\u001b[0m in \u001b[0;36m<cell line: 14>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;31m# Train the model using these generators\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m autoencoder_classifier.fit(\n\u001b[0m\u001b[1;32m     15\u001b[0m     \u001b[0mtrain_generator\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m     \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m50\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0;31m# Or your desired number of epochs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     63\u001b[0m         \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 65\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     66\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m             \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1781\u001b[0m                         ):\n\u001b[1;32m   1782\u001b[0m                             \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1783\u001b[0;31m                             \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1784\u001b[0m                             \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1785\u001b[0m                                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py\u001b[0m in \u001b[0;36mtrain_function\u001b[0;34m(iterator)\u001b[0m\n\u001b[1;32m   1375\u001b[0m             \u001b[0;32mdef\u001b[0m \u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1376\u001b[0m                 \u001b[0;34m\"\"\"Runs a training execution with a single step.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1377\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mstep_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1378\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1379\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_eagerly\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py\u001b[0m in \u001b[0;36mstep_function\u001b[0;34m(model, iterator)\u001b[0m\n\u001b[1;32m   1357\u001b[0m                     \u001b[0mrun_step\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mjit_compile\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreduce_retracing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1358\u001b[0m                 )\n\u001b[0;32m-> 1359\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1360\u001b[0m             \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdistribute_strategy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_step\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1361\u001b[0m             outputs = reduce_per_replica(\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/data/ops/iterator_ops.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    807\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m__next__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    808\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 809\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_internal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    810\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOutOfRangeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    811\u001b[0m       \u001b[0;32mraise\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/data/ops/iterator_ops.py\u001b[0m in \u001b[0;36m_next_internal\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    770\u001b[0m     \u001b[0;31m# to communicate that there is no more data to iterate over.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    771\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecution_mode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSYNC\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 772\u001b[0;31m       ret = gen_dataset_ops.iterator_get_next(\n\u001b[0m\u001b[1;32m    773\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterator_resource\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    774\u001b[0m           \u001b[0moutput_types\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_flat_output_types\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/ops/gen_dataset_ops.py\u001b[0m in \u001b[0;36miterator_get_next\u001b[0;34m(iterator, output_types, output_shapes, name)\u001b[0m\n\u001b[1;32m   3021\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mtld\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_eager\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3022\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3023\u001b[0;31m       _result = pywrap_tfe.TFE_Py_FastPathExecute(\n\u001b[0m\u001b[1;32m   3024\u001b[0m         \u001b[0m_ctx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"IteratorGetNext\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"output_types\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_types\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3025\u001b[0m         \"output_shapes\", output_shapes)\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Adjust the test dataset\n",
        "def prepare_test_data(images, labels):\n",
        "    # Ensure the structure is correct: (images, [images, labels])\n",
        "    return images, (images, labels)\n",
        "\n",
        "# Apply the function to the test dataset\n",
        "test_data = test_ds.map(prepare_test_data)\n",
        "\n",
        "\n",
        "# Evaluate the model\n",
        "results = autoencoder_classifier.evaluate(test_data)\n",
        "print(f\"Test Loss: {results[0]}\")\n",
        "print(f\"Test Reconstruction Loss: {results[1]}\")\n",
        "print(f\"Test Classification Loss: {results[2]}\")\n",
        "print(f\"Test Reconstruction Accuracy: {results[3]}\")\n",
        "print(f\"Test Classification Accuracy: {results[4]}\")\n",
        "print(f\"Test Precision: {results[5]}\")\n",
        "print(f\"Test Recall: {results[6]}\")\n",
        "print(f\"Test F1 Score: {results[7]}\")  # F1 score result\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M09V0w8q5iO5",
        "outputId": "7bf10db7-ad41-402b-da2f-e2317aed5d33"
      },
      "execution_count": 126,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "125/125 [==============================] - 9s 72ms/step - loss: 1.0356 - conv2d_46_loss: 0.0106 - dense_29_loss: 0.9673 - conv2d_46_accuracy: 0.0367 - dense_29_accuracy: 0.5698 - dense_29_precision_16058: 0.7314 - dense_29_recall_16058: 0.3077 - dense_29_f1_score: 0.4332\n",
            "Test Loss: 1.0356038808822632\n",
            "Test Reconstruction Loss: 0.010560151189565659\n",
            "Test Classification Loss: 0.967251181602478\n",
            "Test Reconstruction Accuracy: 0.03667861968278885\n",
            "Test Classification Accuracy: 0.5697500109672546\n",
            "Test Precision: 0.7314319610595703\n",
            "Test Recall: 0.30774998664855957\n",
            "Test F1 Score: 0.43322181701660156\n"
          ]
        }
      ]
    }
  ]
}